{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos predictivos de regresión lineal uni-variable utilizando Tensorflow\n",
    "Por Rodolfo Antonio Zea Posadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El presente jupyter notebook hace referencia a este [link](https://github.com/razp26/python-jupyterNotebooks/blob/master/Python%20para%20Data%20Science/Proyecto/Proyecto%20-%20Modelos%20predictivos%20de%20regresi%C3%B3n%20lineal%20uni-variable.ipynb) \n",
    "\n",
    "En esta ocasión, utilizaremos el mismo set de datos y elegiremos una variable independiente (Overall_Quality) para crear un modelo de regresión lineal para calcular el valor de la variable dependiente SalePrace. \n",
    "\n",
    "# Análisis inicial\n",
    "El método de optimizador que estaremos utilizando es el de Gradient Descent. En resumen, este método consiste en acercarse a un mínimo (local o global) de la función moviéndose, en cada iteración, el valor del “earning rate, en sentido contrario al valor de la derivada de la función de costo.\n",
    "Tomando como consideración lo anterior, es probable que con un learning rate muy alto, sea muy difícil lograr una aproximación al valor mínimo deseado. Se estima que a medida que el learning rate disminuye, el cálculo del costo (error) es más preciso, sin embargo, si este llega a un punto muy pequeño, puede que sea muy difícil aproximarse al valor deseado.\n",
    "\n",
    "El primer paso consiste en importar las librerías que utilizaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación procedemos a cargar la información del data set. Para ello, utilizaremos el 80% de los datos como datos de entrenamiento y el 20% de los datos como datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('proyecto_training_data.npy')\n",
    "# 80% de los datos para datos de entrenamiento\n",
    "n_train_rows = int(np.shape(data)[0]*0.8)\n",
    "data_train = data[0:n_train_rows]\n",
    "\n",
    "# 20% de los datos para datos de prueba\n",
    "n_test_rows = int(np.shape(data)[0]*0.2)\n",
    "data_test = data[-1*n_test_rows:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hemos cargado nuestro data set y lo hemos separado en datos de entrenamiento y datos de prueba, procedemos a extraer de este los valores de las variables que utilizaremos para ejemplificar la regresión lineal utilizando Tensforflow.\n",
    "\n",
    "Las variables que utilizaremos son OverallQuality (x) y SalePrice(y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos los datos de entrenamiento de la variable Overall Quality\n",
    "x_overall_quality = data_train[:,1]\n",
    "y_overall_quality = data_train[:,0]\n",
    "\n",
    "# Número de ephochs\n",
    "epochs_overall_quality = 60000\n",
    "\n",
    "# Cada cuantos epochs se imprime el resultado del error\n",
    "imprimir_error_cada_overall_quality = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo_lineal_tf(x, y, epochs, imprimir_error_cada, lrs):\n",
    "    \n",
    "    # Creamos el grafo que utilizaremos\n",
    "    grafo = tf.Graph()\n",
    "    with grafo.as_default():\n",
    "    \n",
    "        # Definimos nuestros placeholders\n",
    "        X = tf.placeholder(tf.float32, name=\"X\") \n",
    "        Y = tf.placeholder(tf.float32, name=\"Y\")\n",
    "        LR = tf.placeholder(tf.float32, name=\"LR\")\n",
    "\n",
    "        # Declaramos dos variables, una para los \"weights\" y la otra para \"biases\" y los inicializaremos con valores aleatorios.\n",
    "        m = tf.Variable(np.random.randn(), name=\"m\")\n",
    "        b = tf.Variable(np.random.randn(), name=\"b\")\n",
    "\n",
    "        # Calculamos la cantidad de registros, como un valor constante, de x\n",
    "        n = np.shape(x)[0]\n",
    "\n",
    "        # Construimos la hipótesis o modelo de regresion lineal \n",
    "        yhat = m*X + b\n",
    "\n",
    "        # Definimos la función de costo (error)\n",
    "        costo = tf.reduce_sum(tf.square(yhat-Y)) / (2 * n)\n",
    "        \n",
    "        # Creamos nuestro resumen de tipo scalar\n",
    "        costo_summary = tf.summary.scalar(name='costo_summary', tensor=costo)\n",
    "        \n",
    "        # Definimos el optimizador de Gradient Descent\n",
    "        optimizador = tf.train.GradientDescentOptimizer(LR).minimize(costo)\n",
    "        \n",
    "        # Recorremos nuestro vector de learning rates\n",
    "        for lr in np.nditer(lrs):\n",
    "            \n",
    "            # Imprimimos el learning reate a utilizar en la iteración\n",
    "            print('Learning rate: ', lr)\n",
    "\n",
    "            # Inicializamos las variables globales\n",
    "            init = tf.global_variables_initializer()\n",
    "\n",
    "            # Inicializamos el grafo\n",
    "            with tf.Session(graph = grafo) as session:\n",
    "                \n",
    "                # Creamos un writer para nuestros logs en tensorboard\n",
    "                writer = tf.summary.FileWriter('./grafos/lr=' + str(lr), session.graph)\n",
    "\n",
    "                # Inicializamos las variables en la sesión\n",
    "                session.run(init)\n",
    "\n",
    "                # Iteramos el número de veces que indica el parámetro \"epochs\"\n",
    "                for epoch in range(epochs):\n",
    "\n",
    "                    # Ejecutamos el paso de gradient descent\n",
    "                    session.run(optimizador, feed_dict = {X: x, Y: y, LR: lr})\n",
    "                    \n",
    "                    summary = session.run(costo_summary, feed_dict = {X: x, Y: y, LR: lr})\n",
    "                    writer.add_summary(summary, epoch)\n",
    "                    \n",
    "                    # Verificamos si debemos de imprimir el resultado\n",
    "                    if (epoch + 1) % imprimir_error_cada == 0:\n",
    "\n",
    "                        # Calculamos el costo de cada epoch\n",
    "                        c = session.run(costo, feed_dict = {X: x, Y: y})\n",
    "                        print('Iteración: ' + str(epoch + 1))\n",
    "                        print('Error del modelo: ', c)\n",
    "\n",
    "                # Obtenemos el costo y los estimados para Weights y Bias\n",
    "                costos = session.run(costo, feed_dict = {X: x, Y: y})\n",
    "                weights = session.run(m)\n",
    "                bias = session.run(b)\n",
    "                \n",
    "                # Cerramos el writer\n",
    "                writer.close()\n",
    "                \n",
    "                # Imrpimimos los valores finales\n",
    "                print('********** VALORES FINALES **********')\n",
    "                print('Costos: ', costos)\n",
    "                print('Weights: ', weights)\n",
    "                print('Bias: ', bias)\n",
    "                print('*************** ***************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hemos definido nuestra función que calcula el modelo de regresión lineal utilizando Tensorflow, procedemos a invocarla utilizando distintos learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Chofo\\Anaconda3\\envs\\galileo_python\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Chofo\\Anaconda3\\envs\\galileo_python\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Learning rate:  10.0\n",
      "Iteración: 10000\n",
      "Error del modelo:  nan\n",
      "Iteración: 20000\n",
      "Error del modelo:  nan\n",
      "Iteración: 30000\n",
      "Error del modelo:  nan\n",
      "Iteración: 40000\n",
      "Error del modelo:  nan\n",
      "Iteración: 50000\n",
      "Error del modelo:  nan\n",
      "Iteración: 60000\n",
      "Error del modelo:  nan\n",
      "********** VALORES FINALES **********\n",
      "Costos:  nan\n",
      "Weights:  nan\n",
      "Bias:  nan\n",
      "*************** ***************\n",
      "Learning rate:  1.0\n",
      "Iteración: 10000\n",
      "Error del modelo:  nan\n",
      "Iteración: 20000\n",
      "Error del modelo:  nan\n",
      "Iteración: 30000\n",
      "Error del modelo:  nan\n",
      "Iteración: 40000\n",
      "Error del modelo:  nan\n",
      "Iteración: 50000\n",
      "Error del modelo:  nan\n",
      "Iteración: 60000\n",
      "Error del modelo:  nan\n",
      "********** VALORES FINALES **********\n",
      "Costos:  nan\n",
      "Weights:  nan\n",
      "Bias:  nan\n",
      "*************** ***************\n",
      "Learning rate:  0.1\n",
      "Iteración: 10000\n",
      "Error del modelo:  nan\n",
      "Iteración: 20000\n",
      "Error del modelo:  nan\n",
      "Iteración: 30000\n",
      "Error del modelo:  nan\n",
      "Iteración: 40000\n",
      "Error del modelo:  nan\n",
      "Iteración: 50000\n",
      "Error del modelo:  nan\n",
      "Iteración: 60000\n",
      "Error del modelo:  nan\n",
      "********** VALORES FINALES **********\n",
      "Costos:  nan\n",
      "Weights:  nan\n",
      "Bias:  nan\n",
      "*************** ***************\n",
      "Learning rate:  0.01\n",
      "Iteración: 10000\n",
      "Error del modelo:  1146935200.0\n",
      "Iteración: 20000\n",
      "Error del modelo:  1146916100.0\n",
      "Iteración: 30000\n",
      "Error del modelo:  1146916100.0\n",
      "Iteración: 40000\n",
      "Error del modelo:  1146916100.0\n",
      "Iteración: 50000\n",
      "Error del modelo:  1146916100.0\n",
      "Iteración: 60000\n",
      "Error del modelo:  1146916100.0\n",
      "********** VALORES FINALES **********\n",
      "Costos:  1146916100.0\n",
      "Weights:  45410.65\n",
      "Bias:  -96460.945\n",
      "*************** ***************\n",
      "Learning rate:  0.001\n",
      "Iteración: 10000\n",
      "Error del modelo:  1243064400.0\n",
      "Iteración: 20000\n",
      "Error del modelo:  1184215300.0\n",
      "Iteración: 30000\n",
      "Error del modelo:  1161386200.0\n",
      "Iteración: 40000\n",
      "Error del modelo:  1152530000.0\n",
      "Iteración: 50000\n",
      "Error del modelo:  1149094300.0\n",
      "Iteración: 60000\n",
      "Error del modelo:  1147761500.0\n",
      "********** VALORES FINALES **********\n",
      "Costos:  1147761500.0\n",
      "Weights:  44490.16\n",
      "Bias:  -90566.1\n",
      "*************** ***************\n",
      "Learning rate:  0.0001\n",
      "Iteración: 10000\n",
      "Error del modelo:  1372377900.0\n",
      "Iteración: 20000\n",
      "Error del modelo:  1352009900.0\n",
      "Iteración: 30000\n",
      "Error del modelo:  1333481200.0\n",
      "Iteración: 40000\n",
      "Error del modelo:  1316626800.0\n",
      "Iteración: 50000\n",
      "Error del modelo:  1301296600.0\n",
      "Iteración: 60000\n",
      "Error del modelo:  1287348600.0\n",
      "********** VALORES FINALES **********\n",
      "Costos:  1287348600.0\n",
      "Weights:  33529.58\n",
      "Bias:  -20372.182\n",
      "*************** ***************\n"
     ]
    }
   ],
   "source": [
    "# Creamos un arreglo en donde almacenaremos los distintos learning rates que tendremos\n",
    "learning_rates_overall_quality = np.array([10,1,0.1,0.01,0.001,0.0001])\n",
    "\n",
    "# Ejecutamos nuestra función que construye el modelo regresión lineal.\n",
    "modelo_lineal_tf(x_overall_quality, y_overall_quality, epochs_overall_quality, imprimir_error_cada_overall_quality, learning_rates_overall_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que hemos completado la ejecución de la función para obtener un modelo de regresión lineal para distintos learning rates, mostramos el grafo computacional de Tensorflow obtenido con la herramienta Tensorboard.\n",
    "\n",
    "![title](grafos/grafo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusión\n",
    "Como punto de partida para explicar la conclusión obtenida, mostramos una gráfica (obtenida utilizando la herramienta Tensorboard) que nos permite ver el comportamiento del costo (error) en la estimación de los parámetros de regresión, para cada uno de los learning rates utilizados.\n",
    "\n",
    "![title](grafos/costo_summary.png)\n",
    "\n",
    "![title](grafos/costo_summary2.png)\n",
    " \n",
    "A manera de conclusión, podemos decir que el learning rate que mejor predice el modelo de regresión lineal, ya que produce el menor error (costo) es cuando tiene el valor de 0.01. Si se ve el la bitácora de ejecución, es posible observar que ya para la iteración 20,000 ya se había alcanzado este valor mínimo de error. \n",
    "\n",
    "Por este motivo, concluimos que se consigue el mejor modelo de regresión lineal entre las variables X (OverallQuality) y Y (SalePrice) con un learning rate de 0.01.\n",
    "\n",
    "El modelo final queda de la siguiente manera:\n",
    "\n",
    "Y = 45410.65X -96460.945\n",
    "\n",
    "Traducido a las variables seleccionadas\n",
    "\n",
    "SalePrice = 45410.65OverallQuality -96460.945\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
