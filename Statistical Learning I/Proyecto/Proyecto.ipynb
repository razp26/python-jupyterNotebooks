{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1: Entrenamiento, validación y selección\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerias que utilizaremos a lo largo del proyecto\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-val-test-split\n",
    "\n",
    "El primer es dar un vistazo a los datos con los que se cuenta. Iniciamos validando el tipo de dato de cada uno de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    }
   ],
   "source": [
    "# Iniciamos leyendo el archivo de entrada\n",
    "dataset = pd.read_csv(\"data_titanic_proyecto.csv\")\n",
    "\n",
    "# Contamos el número de regisitros y el numero de columnas que tiene el dataset\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId             int64\n",
       "Name                   object\n",
       "Age                   float64\n",
       "SibSp                   int64\n",
       "Parch                   int64\n",
       "Ticket                 object\n",
       "Fare                  float64\n",
       "Cabin                  object\n",
       "Embarked               object\n",
       "passenger_class        object\n",
       "passenger_sex          object\n",
       "passenger_survived     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vemos el tipo de dato que tiene cada columna en el dataset\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Porcentaje NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>19.865320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>77.104377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>0.224467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_class</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_sex</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_survived</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Porcentaje NaN\n",
       "PassengerId               0.000000\n",
       "Name                      0.000000\n",
       "Age                      19.865320\n",
       "SibSp                     0.000000\n",
       "Parch                     0.000000\n",
       "Ticket                    0.000000\n",
       "Fare                      0.000000\n",
       "Cabin                    77.104377\n",
       "Embarked                  0.224467\n",
       "passenger_class           0.000000\n",
       "passenger_sex             0.000000\n",
       "passenger_survived        0.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculamos el portancaje de NaN en nuestro dataset\n",
    "pd.DataFrame({'Porcentaje NaN': dataset.isnull().sum() * 100 / len(dataset)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con base al análisis anterior, procedemos a descartar los features de: PassengerId, Name, Ticket y Cabin.\n",
    "\n",
    "La columna 'Cabin' se descarta debido a que posee un 77% de datos NaN los cuales representan una gran incertidumbre. A continuación procedemos a definir 3 variables, una que contendrá las features que no se utilizarán, otra que contendrá las features categoricas y la última el nombre del feature a predecir, en este caso será passenger_survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(ds, useless_features, categorical_features):\n",
    "    \n",
    "    # Eliminamos las features que no se utilizaran del dataset\n",
    "    ds = ds.drop(useless_features, axis=1)\n",
    "    \n",
    "    # Normalizamos las variables que no son categoricas\n",
    "    # Sustituiremos los valores NaN por el valor de la media\n",
    "    imputer = Imputer(strategy=\"median\")\n",
    "    ds_numeric_features = ds.drop(categorical_features, axis=1)\n",
    "    imputer.fit(ds_numeric_features)\n",
    "    ds_imputer = imputer.transform(ds_numeric_features)\n",
    "    ds_numeric_features = pd.DataFrame(ds_imputer, columns=ds_numeric_features.columns)\n",
    "    \n",
    "    # Normalizamos las variables categoricas\n",
    "    ds_categorical_features = ds.drop(ds_numeric_features.columns, axis=1)\n",
    "    ds_categorical_features_encoded = pd.DataFrame()\n",
    "    \n",
    "    # Sustituiremos los valores NaN por 'NaN'\n",
    "    ds_categorical_features = ds_categorical_features.replace(np.nan, 'NaN', regex=True)\n",
    "    \n",
    "    # Usamos LabelEncoder para convertir nuestros valores categoricos a numericos\n",
    "    ds_categorical_features = ds_categorical_features.apply(LabelEncoder().fit_transform)\n",
    "    ds_categorical_features = pd.DataFrame(ds_categorical_features, columns= ds_categorical_features.columns)\n",
    "    \n",
    "    # Concatenamos nuestros dos DataFrames\n",
    "    ds[categorical_features] = ds_categorical_features[categorical_features].values\n",
    "    ds[ds_numeric_features.columns] = ds_numeric_features.values\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  SibSp  Parch      Fare  Embarked  passenger_class  passenger_sex  \\\n",
      "0    22.0    1.0    0.0    7.2500         3                0              1   \n",
      "1    38.0    1.0    0.0   71.2833         0                2              0   \n",
      "2    26.0    0.0    0.0    7.9250         3                0              0   \n",
      "3    35.0    1.0    0.0   53.1000         3                2              0   \n",
      "4    35.0    0.0    0.0    8.0500         3                0              1   \n",
      "5    28.0    0.0    0.0    8.4583         2                0              1   \n",
      "6    54.0    0.0    0.0   51.8625         3                2              1   \n",
      "7     2.0    3.0    1.0   21.0750         3                0              1   \n",
      "8    27.0    0.0    2.0   11.1333         3                0              0   \n",
      "9    14.0    1.0    0.0   30.0708         0                1              0   \n",
      "10    4.0    1.0    1.0   16.7000         3                0              0   \n",
      "11   58.0    0.0    0.0   26.5500         3                2              0   \n",
      "12   20.0    0.0    0.0    8.0500         3                0              1   \n",
      "13   39.0    1.0    5.0   31.2750         3                0              1   \n",
      "14   14.0    0.0    0.0    7.8542         3                0              0   \n",
      "15   55.0    0.0    0.0   16.0000         3                1              0   \n",
      "16    2.0    4.0    1.0   29.1250         2                0              1   \n",
      "17   28.0    0.0    0.0   13.0000         3                1              1   \n",
      "18   31.0    1.0    0.0   18.0000         3                0              0   \n",
      "19   28.0    0.0    0.0    7.2250         0                0              0   \n",
      "20   35.0    0.0    0.0   26.0000         3                1              1   \n",
      "21   34.0    0.0    0.0   13.0000         3                1              1   \n",
      "22   15.0    0.0    0.0    8.0292         2                0              0   \n",
      "23   28.0    0.0    0.0   35.5000         3                2              1   \n",
      "24    8.0    3.0    1.0   21.0750         3                0              0   \n",
      "25   38.0    1.0    5.0   31.3875         3                0              0   \n",
      "26   28.0    0.0    0.0    7.2250         0                0              1   \n",
      "27   19.0    3.0    2.0  263.0000         3                2              1   \n",
      "28   28.0    0.0    0.0    7.8792         2                0              0   \n",
      "29   28.0    0.0    0.0    7.8958         3                0              1   \n",
      "..    ...    ...    ...       ...       ...              ...            ...   \n",
      "861  21.0    1.0    0.0   11.5000         3                1              1   \n",
      "862  48.0    0.0    0.0   25.9292         3                2              0   \n",
      "863  28.0    8.0    2.0   69.5500         3                0              0   \n",
      "864  24.0    0.0    0.0   13.0000         3                1              1   \n",
      "865  42.0    0.0    0.0   13.0000         3                1              0   \n",
      "866  27.0    1.0    0.0   13.8583         0                1              0   \n",
      "867  31.0    0.0    0.0   50.4958         3                2              1   \n",
      "868  28.0    0.0    0.0    9.5000         3                0              1   \n",
      "869   4.0    1.0    1.0   11.1333         3                0              1   \n",
      "870  26.0    0.0    0.0    7.8958         3                0              1   \n",
      "871  47.0    1.0    1.0   52.5542         3                2              0   \n",
      "872  33.0    0.0    0.0    5.0000         3                2              1   \n",
      "873  47.0    0.0    0.0    9.0000         3                0              1   \n",
      "874  28.0    1.0    0.0   24.0000         0                1              0   \n",
      "875  15.0    0.0    0.0    7.2250         0                0              0   \n",
      "876  20.0    0.0    0.0    9.8458         3                0              1   \n",
      "877  19.0    0.0    0.0    7.8958         3                0              1   \n",
      "878  28.0    0.0    0.0    7.8958         3                0              1   \n",
      "879  56.0    0.0    1.0   83.1583         0                2              0   \n",
      "880  25.0    0.0    1.0   26.0000         3                1              0   \n",
      "881  33.0    0.0    0.0    7.8958         3                0              1   \n",
      "882  22.0    0.0    0.0   10.5167         3                0              0   \n",
      "883  28.0    0.0    0.0   10.5000         3                1              1   \n",
      "884  25.0    0.0    0.0    7.0500         3                0              1   \n",
      "885  39.0    0.0    5.0   29.1250         2                0              0   \n",
      "886  27.0    0.0    0.0   13.0000         3                1              1   \n",
      "887  19.0    0.0    0.0   30.0000         3                2              0   \n",
      "888  28.0    1.0    2.0   23.4500         3                0              0   \n",
      "889  26.0    0.0    0.0   30.0000         0                2              1   \n",
      "890  32.0    0.0    0.0    7.7500         2                0              1   \n",
      "\n",
      "     passenger_survived  \n",
      "0                     0  \n",
      "1                     1  \n",
      "2                     1  \n",
      "3                     1  \n",
      "4                     0  \n",
      "5                     0  \n",
      "6                     0  \n",
      "7                     0  \n",
      "8                     1  \n",
      "9                     1  \n",
      "10                    1  \n",
      "11                    1  \n",
      "12                    0  \n",
      "13                    0  \n",
      "14                    0  \n",
      "15                    1  \n",
      "16                    0  \n",
      "17                    1  \n",
      "18                    0  \n",
      "19                    1  \n",
      "20                    0  \n",
      "21                    1  \n",
      "22                    1  \n",
      "23                    1  \n",
      "24                    0  \n",
      "25                    1  \n",
      "26                    0  \n",
      "27                    0  \n",
      "28                    1  \n",
      "29                    0  \n",
      "..                  ...  \n",
      "861                   0  \n",
      "862                   1  \n",
      "863                   0  \n",
      "864                   0  \n",
      "865                   1  \n",
      "866                   1  \n",
      "867                   0  \n",
      "868                   0  \n",
      "869                   1  \n",
      "870                   0  \n",
      "871                   1  \n",
      "872                   0  \n",
      "873                   0  \n",
      "874                   1  \n",
      "875                   1  \n",
      "876                   0  \n",
      "877                   0  \n",
      "878                   0  \n",
      "879                   1  \n",
      "880                   1  \n",
      "881                   0  \n",
      "882                   0  \n",
      "883                   0  \n",
      "884                   0  \n",
      "885                   0  \n",
      "886                   0  \n",
      "887                   1  \n",
      "888                   0  \n",
      "889                   1  \n",
      "890                   0  \n",
      "\n",
      "[891 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chofo\\Anaconda3\\envs\\galileo_python\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos feature engineering para normalizar los datos a una forma que no sea útil\n",
    "useless_features = np.array(['PassengerId','Name','Ticket', 'Cabin'])\n",
    "categorical_features = np.array(['passenger_sex','Embarked','passenger_class','passenger_survived'])\n",
    "normalized_dataset = feature_engineering(dataset, useless_features, categorical_features)\n",
    "\n",
    "print (normalized_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego que hemos hecho feature_engineering sobre nuestra data para normalizarla, procedemos a crear nuestros distintos datasets que utilizaremos para entrenar, validar y probar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de los datos de entrenamiento:  (605, 7) (605,)\n",
      "Shape de los datos de validación (107, 7) (107,)\n",
      "Shape de los datos de prueba (179, 7) (179,)\n"
     ]
    }
   ],
   "source": [
    "# Hacemos una copia de nuestro dataset normalizado sin incluir la variable a predecir\n",
    "ds_x = normalized_dataset.drop('passenger_survived', axis=1)\n",
    "\n",
    "predict_feature = 'passenger_survived'\n",
    "ds_y = normalized_dataset[predict_feature].copy()\n",
    "\n",
    "# Separamos nuestros datos en datos de prueba y datos de entrenamiento\n",
    "# Utiliazaremos el 80% como datos de entrenamiento\n",
    "x_train, x_test, y_train, y_test = train_test_split(ds_x, ds_y, train_size=0.8)\n",
    "\n",
    "# Utilizamos los datos de entrenamiento para extraer una porción para datos de validación.\n",
    "# Utilizaremos un 20% del dataset de entrenamiento para datos de validación\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, train_size=0.85)\n",
    "\n",
    "print('Shape de los datos de entrenamiento: ', x_train.shape, y_train.shape)\n",
    "print('Shape de los datos de validación', x_validation.shape, y_validation.shape)\n",
    "print('Shape de los datos de prueba', x_test.shape, y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
